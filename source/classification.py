# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Frv8irxb4CK9mEJYXcuORATfl6dw_hon
"""

# Commented out IPython magic to ensure Python compatibility.
# necessary imports
import os
from tensorflow import  keras
from tensorflow.keras import applications
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras import backend as K
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import cv2
import scipy
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

# load pre-trained model
loaded_model = load_model(r'/content/drive/MyDrive/Data_challenge/models2/new-model-19-0.99.hdf5')

def get_class_activation_map(model, img):
    ''' 
    this function computes the class activation map
    
    Inputs:
        1) model (tensorflow model) : trained model
        2) img (numpy array of shape (224, 224, 3)) : input image
    '''
    
    # expand dimension to fit the image to a network accepted input size
    img = np.expand_dims(img, axis=0)

    # predict to get the winning class
    predictions = model.predict(img)
    label_index = np.argmax(predictions)
    confidence= predictions[0][label_index]*100
    confidence=round(confidence,2)
    # Get the 2048 input weights to the softmax of the winning class.
    class_weights = model.layers[-4].get_weights()[0]
    class_weights_winner = class_weights[:, label_index]
    
    # get the final conv layer
    final_conv_layer = model.get_layer("out_relu") #Conv_1_bn
    
    # create a function to fetch the final conv layer output maps (should be shape (1, 7, 7, 2048)) 
    get_output = K.function([model.layers[0].input],[final_conv_layer.output, model.layers[-1].output])
    [conv_outputs, predictions] = get_output([img])
    
    # squeeze conv map to shape image to size (7, 7, 2048)
    conv_outputs = np.squeeze(conv_outputs)

    
    # bilinear upsampling to resize each filtered image to size of original image 
    mat_for_mult = scipy.ndimage.zoom(conv_outputs, (32, 32, 1), order=1) # dim: 224 x 224 x 1280
    # get class activation map for object class that is predicted to be in the image
    final_output = np.dot(mat_for_mult.reshape((224*224, 1280)), class_weights_winner).reshape(224,224) # dim: 224 x 224
    
    # return class activation map
    return final_output, label_index,confidence

def get_bounding_box(CAM, img, label_index):
    ''' 
    this function plots the activation map 
    
    Inputs:
        1) CAM (numpy array of shape (224, 224)) : class activation map containing the trained heat map
        2) img (numpy array of shape (224, 224, 3)) : input image
        3) label (uint8) : index of the winning class
    '''
    if(label_index==0):
      # plot image
      # plot class activation map
      CAM2 = image.img_to_array(CAM, dtype='uint8')
      thresh = cv2.threshold(CAM2, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
      # Find contours
      cnts = cv2.findContours(CAM2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
      cnts = cnts[0] if len(cnts) == 2 else cnts[1]
      coordinates=[]
      for c in cnts:
          x,y,w,h = cv2.boundingRect(c)
          coordinates.append([x,y,w,h])
    else :
      coordinates=[0,0,0,0]

    
    # get string for classified class
    max=0
    for i in range (len(coordinates)):
      if (coordinates[i][2] > max) : 
        max= coordinates[i][2] 
        index=i
    class_list = ['Defected' , 'Not defected']
    label_class_name = class_list[label_index]
    return label_class_name, coordinates[index]

def get_classification_summary(model, img):
    '''
    this function creates and plots six class activation maps
    
    Inputs:
        1) model (tensorflow model) : trained model used for the prediction and conv outputs
        2) count_CAMs (uint8) : count of activation maps that shall be plotted
        3) images (numpy array of shape (batch_size, 224, 224, 3)) : array containing the images 
        4) data_path (string) : string containing the path to the images
        5) batch_size (uint8) : number of images 
    '''
    
    img=img/255
    CAM, label,confidence = get_class_activation_map(model, img)
    label_class_name,coordinates=get_bounding_box(CAM, img, label)
    return label,confidence,label_class_name,coordinates

img1 = cv2.imread('/content/AE00018_023038_00_4_1_2001.jpg')
img_width, img_height = 224, 224
dim=(img_width, img_height)
img = cv2.resize(img1, dim, interpolation = cv2.INTER_AREA)
label,confidence,label_class_name, coordinates=get_classification_summary(loaded_model, img)

print(label,confidence,label_class_name, coordinates)
